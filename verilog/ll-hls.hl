% literate:

\section{HLS backend}

This is a very simple HLS backend for the LLVM IR generated by CLike frontend, to be
used alongside with the Verilog inlining experiments and Small$*$ SoC.

A C function is translated into a single FSM, in some cases, maybe, including
synthesised pipelines if it is possible to infer static loop properties (or if hinted
explicitly). Local arrays are translated into memories, and at the moment there is no
way to synthesise an access to an external memory bus (but should be relatively easy
to do).

\subsection{Outline}

Restrictions:

\begin{itemize}
\item Do not call things "clk", "reset", "ACK" and "REQ".
\item Do not call labels 'IDLE' and 'entry'.
\item Only array allocas are allowed (representing memories); Only GEPs over directly allocaded arrays are allowed - i.e., no registers storing pointers;
\item Only integer and integer pointer function arguments are allowed, with pointers representing outputs
\item Function must return void
\item No recursion, no non-intrinsic function calls. Everything is inlined
\end{itemize}

Output restrictions:

\begin{itemize}
\item Fully syncronous, single clock
\item Implicit clock, reset, req and ack signals
\end{itemize}

Translation:

\begin{itemize}
\item Code is translated into an FSM, initially by a direct mapping of basic blocks to states
\item Parallelism is exploited within a basic block level only. Later we'll try to split FSMs.
\end{itemize}


Translation pipeline:
\begin{itemize}
\item Generic SSA optimisations, with a twist: all the non-memory if branches are converted into selects.
\item Redundant GEPs must be eliminated in IR: {\sl (gep (alloca) 0 0)} and alike.
\item Within each basic block, split the entries into par and seq sub-blocks;
      Rules are following: same memory accesses are ordered (reads may be grouped), dependencies are obviously ordered, anything else is independent.

(Optional, to be done later) Order memory access smarter, e.g., group reads together and infer multi--port access.
\item (Optional, to be done later) identifying loops that can be turned into pipelines;
      If loop induction variables are "{\sl simple}" (whatever the fuck it means), internal sequence of par blocks
      may be converted into a detached pipeline, with induction variables being issued by a newly introduced FSM loop.
      Now back to our fucks: induction variables are {\sl simple} iff their loops are shorter than the loop body. E.g,
      a counter with loop invariant bounds is definitely {\sl simple}. For now, we will only do this transform for the
      loops that do not access the same memory in different stages. Later it may be possible to consider allowing something like
      a $2-$port read, $1-$port write scenario. We only do this for the innermost loops (TODO: why, actually?). All the pipeline stages
      must be strictly sequential basic blocks (i.e., all the internal branching is already resolved with selects).
      \begin{itemize}
        \item All pipeline stages are treated as one big par block, and are considered parallel with the control loop FSM stages.
        \item Also, this behaviour can be triggered explicitly with a pragma. Then, even if induction variables are not simple,
              a pipeline is still generated, with an output stored in a long vector instead (pipeline depth $=$ number of threads $=$ output width
              must be specified explicitly, because).
      \end{itemize}
\item Split basic blocks after the par blocks containing at least one delayed memory access operation.
\item Applying cost model to the sequential sub--blocks, breaking into smaller blocks if necessary.
\item Marking the SSA "registers" that are only used within their block (FSM stage) as wires, and
      persistent as "registers".
\item Cleanup stage --- if a register (as in register register, not just an SSA register, kinda) value is read in the same
      FSM stage, a wire value must be lifted and assigned both to the register and to its local uses.
\item (Optional) A possible optimisation - code motion from previous FSM steps/pipeline stages to reduce numbers of
      registers while maintaining the costs
\item Doing a register allocation to save area
\item Enumerating compute blocks that can be reused:
   \begin{itemize}
     \item For each par block, operations are enumerated; There is a budget for small adders and logical
           operations that are not counted (because cost of multiplexing ALU inputs/outputs would be higher than
           synthesising a small operation in place).
     \item A superposition of the operations of all the FSM stages are synthesised into one wide ALU block, with multiplexing
           inputs and outputs by the FSM stage number.
   \end{itemize}
\item (Optional) for the pipelines, infer pipeline registers (pass all the non--invariant values through all the stages down to
      their uses)
\item Converting small basic blocks to FSM/pipeline stages
\item Final code generation
\end{itemize}

\phcode{include "extra.hl"}

\phcode{litinclude "ll-opt-hls.hl"}

\phcode{litinclude "ll-hls-asts.hl"}
\input ll-hls-asts.tex

\phcode{litinclude "ll-hls-utils.hl"}
\input ll-hls-utils.tex

\phcode{litinclude "ll-hls-lowering1.hl"}
\input ll-hls-lowering1.tex

\phcode{litinclude "ll-hls-schedule.hl"}
\input ll-hls-schedule.tex

\phcode{litinclude "ll-hls-lowering2.hl"}
\input ll-hls-lowering2.tex

\phcode{litinclude "ll-hls-registers.hl"}
\input ll-hls-registers.tex

\phcode{litinclude "ll-hls-explicit.hl"}
\input ll-hls-explicit.tex

\phcode{litinclude "ll-hls-decoration.hl"}
\input ll-hls-decoration.tex

\phcode{litinclude "./ll-hls-regalloc.hl"}
\input ll-hls-regalloc.tex

\phcode{litinclude "./ll-hls-special.hl"}
\input ll-hls-special.tex

\phcode{litinclude "./ll-hls-driver.hl"}
\input ll-hls-driver.tex

\phcode{litinclude "./ll-hls-wrapper.hl"}
\input ll-hls-wrapper.tex

\phcode{include "./ll-hls-backend.hl"}

%%%%%%